{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-10-17-17-20-18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.10.17(월) 수업내용 정리 \n",
    "\n",
    "- 주요내용: dataSet 만드는 다양한 방법 \n",
    "    - 참고로 알아두면 좋을 내용 \n",
    "- 주요 모듈: numpy, glob, pandas \n",
    "\n",
    "- 방법 4가지 \n",
    "    1. 폴더 내 자료 활용 npz 제작 방법 \n",
    "    2. y값을 멀티 레이블로 제작하는 방법 \n",
    "        - blue_shirt 하면 blue는 1, shirt 0으로 \n",
    "    3. 폴더 내 자료 정보 이용, 파일 정보를 csv로 제작하는 방법 \n",
    "    4. 파일정보 csv가 있을 때 npz자료로 제작하는 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이중 FOR 문 활용 \n",
    "\n",
    "![](2022-10-17-17-45-29.png)\n",
    "\n",
    "For 폴더 in 폴더_리스트: \n",
    " 1. 오픈\n",
    "  -clothes_dataset 폴더 내 옷 정보 폴더 오픈 \n",
    "   ex) clothes_dataset> black_dress \n",
    "   \n",
    "For 파일 in 폴더: \n",
    "\n",
    "  2. 읽기\n",
    "    - 폴더 내 이미지파일 읽기 \n",
    "    \n",
    "     ex) clothes_dataset> black_dress > ~.jpg \n",
    "\n",
    "  3. 사이즈 조정\n",
    "    - reshape(180 x 180) \n",
    "\n",
    "  4. numpy 변환\n",
    "    - np.array(itemList)\n",
    "\n",
    "  5. X에 추가 \n",
    "    - x.append(item) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 폴더 내 자료 활용 npz 제작 방법  \n",
    "- 구글드라이브에서 'clothes_dataset' 폴더 다운 받기! \n",
    "- npz: numpy zip \n",
    "    - = numpy 압축\n",
    "    - 2개 이상의 data 한 파일에 저장\n",
    "\n",
    "- 세부 내요 ㅇ\n",
    "    - 폴더명 리스트로 만들기  \n",
    "        - for 이용 + split이나 replace \n",
    "        - os.listdir('../clothes_dataset/') \n",
    "    - 데이터셋 제작 \n",
    "        - class_names: 폴더명을 기록 \n",
    "        - x값(이미지): 폴더 내의 모든 이미지를 읽어서 180,180으로 사이즈 변경 후 제작 \n",
    "        - Y값(레이블): clothes_dataset 폴더의 폴더명을 순서대로 0,1,2,3으로 제작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Start:../clothes_dataset\\black_dress\n",
      "▶️ Start:../clothes_dataset\\black_pants\n",
      "▶️ Start:../clothes_dataset\\black_shirt\n",
      "▶️ Start:../clothes_dataset\\black_shoes\n",
      "▶️ Start:../clothes_dataset\\black_shorts\n",
      "▶️ Start:../clothes_dataset\\blue_dress\n",
      "▶️ Start:../clothes_dataset\\blue_pants\n",
      "▶️ Start:../clothes_dataset\\blue_shirt\n",
      "▶️ Start:../clothes_dataset\\blue_shoes\n",
      "▶️ Start:../clothes_dataset\\blue_shorts\n",
      "▶️ Start:../clothes_dataset\\brown_pants\n",
      "▶️ Start:../clothes_dataset\\brown_shoes\n",
      "▶️ Start:../clothes_dataset\\brown_shorts\n",
      "▶️ Start:../clothes_dataset\\green_pants\n",
      "▶️ Start:../clothes_dataset\\green_shirt\n",
      "▶️ Start:../clothes_dataset\\green_shoes\n",
      "▶️ Start:../clothes_dataset\\green_shorts\n",
      "▶️ Start:../clothes_dataset\\red_dress\n",
      "▶️ Start:../clothes_dataset\\red_pants\n",
      "▶️ Start:../clothes_dataset\\red_shoes\n",
      "▶️ Start:../clothes_dataset\\white_dress\n",
      "▶️ Start:../clothes_dataset\\white_pants\n",
      "▶️ Start:../clothes_dataset\\white_shoes\n",
      "▶️ Start:../clothes_dataset\\white_shorts\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 폴더 내 정보로 npz 만들기 \n",
    "x,y=[],[]\n",
    "folderList=glob('../clothes_dataset/*')\n",
    "for cnt,folder in enumerate(folderList):\n",
    "    fileList=glob(folder + '/*.jpg')\n",
    "    print('▶️ Start:' + folder) \n",
    "    for file in fileList:\n",
    "        img=Image.open(file)\n",
    "        img=img.resize((180,180))\n",
    "        imgArr=np.array(img)\n",
    "        x.append(imgArr)\n",
    "        y.append(cnt)\n",
    "\n",
    "# npz 저장 \n",
    "np.savez('clothes.npz',  Xdata=x,  Ydata=y) \n",
    "\n",
    "# npz 파일 열기 \n",
    "data=np.load('clothes.npz')\n",
    "# list(data) \n",
    "\n",
    "# x,y,폴더명 기록 \n",
    "Xdata=data['Xdata']\n",
    "Ydata=data['Ydata']\n",
    "class_names=data['class_names'] \n",
    "\n",
    "# 테스트 출력 \n",
    "plt.imshow(np.hstack(Xdata[449:453]))\n",
    "print(Ydata[449:453])\n",
    "\n",
    "for x in range(449,453):\n",
    "    print(class_names[Ydata[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 방법1. append할때 replace/split 활용 \n",
    "from glob import glob\n",
    "\n",
    "folderList=glob('../clothes_dataset/*')\n",
    "class_names=[]\n",
    "for f in folderList:\n",
    "    class_names.append(f.replace('../clothes_dataset\\\\',''))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 방법2. os.listdir 활용 \n",
    "import os\n",
    "\n",
    "os.listdir('../clothes_dataset/') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. y값을 멀티 레이블로 제작하는 방법  \n",
    "\n",
    "- 작업1. 폴더명을 두개의 변수로 나누기\n",
    "    - color 변수 출력=> ['balck','bule', 'brown', 'gren', 'red', 'white']\n",
    "    - category 변수 출력=> ['dress', 'pants', 'shirt','shoes', 'shorts']\n",
    "\n",
    "    - 작업순서\n",
    "        - 1번: blac_dress, black_pants 등의 폴더명이 나오게 리스트를 한다.\n",
    "        - 2번: 그 리스트의 0번자료를 읽어서 'black' 과 'dress' 두 개의 글자로 나뉘게 한다.\n",
    "        - 3번: 1번과 2번을 for로 돌려서 color, category 변수에 append한다.\n",
    "        - 4번: color와 category의 변수를 중복제거한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업1. 폴더명을 두개의 변수로 나누기 \n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "folderName='clothes_dataset'\n",
    "splitVar='_'\n",
    "folder='./' + folderName +'/'\n",
    "folderList=os.listdir(folder)\n",
    "\n",
    "itemList=[x.split(splitVar) for x in folderList]\n",
    "itemList=np.array(itemList)\n",
    "\n",
    "item=[list(set(itemList[:,x])) for x in range(np.shape(itemList)[1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 작업2. x,y 데이터를 제작\n",
    "    - x값은 이미지 데이터를 읽어서 180,180 으로 변경한뒤 array화하고\n",
    "    - y값은 color와 category를 읽어서  멀티로 array화함\n",
    "        - 예) black_pants ==>  [0,1]      bule_shirt ==> [1,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업2. x,y 데이터를 제작 \n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image \n",
    "\n",
    "folderName='clothes_dataset'\n",
    "folderList=glob('../'+folderName+'/*')\n",
    "y,x=[],[]\n",
    "\n",
    "for folder in folderList[:3]:\n",
    "    print(folder)\n",
    "    folder=folder.split('\\\\')[-1]\n",
    "    tmp1=folder.split('_')[0]\n",
    "    tmp2=folder.split('_')[1]\n",
    "    fileList=glob(folder + '/*.jpg')\n",
    "\n",
    "    print('▶ Start: '+folder)\n",
    "    for file in fileList:\n",
    "        print(file)\n",
    "        img=Image.open(file) # 이미지파일 오픈 \n",
    "        img=img.resize((180,180)) # 사이즈 변경-180 x 180 \n",
    "        imgArr=np.array(img) # array화 \n",
    "        # print(imgArr) # array 체크 \n",
    "\n",
    "        x.append(imgArr) # x데이터\n",
    "        y.append([]) # y데이터 - y데이터 내 2개 리스트 만드는 방법 \n",
    "        y[-1].append(item[0].index(tmp1))\n",
    "        y[-1].append(item[1].index(tmp2))\n",
    "        \n",
    "np.savez('clothes_multi_label.npz',Xdata=x,Ydata=y,class_names=item) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 파일 정보를 직접 csv로 제작하는 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지정보에 대한 csv 자료가 있는경우\n",
    "- 배포하는 곳에서는 폴더내의 정보를 csv로 기록해서 csv 정보를 배포해야함.\n",
    "- 이 csv정보를 이용하여서 사용자는 레이블 작업을 진행함.\n",
    "\n",
    "### [1] 직접 csv 자료를 제작하여봄.\n",
    "- 이미지와 함께 배포되는 이미지정보.csv 자료를 직접 제작하여 봄\n",
    "- 만약 이미지만 제공될때 일부러 csv정보를 제작할 필요는 없음.\n",
    "    - 앞의 1,2,번 작업만 진행해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "dataList=[]\n",
    "folderList=glob('./clothes_dataset/*')\n",
    "\n",
    "for folder in folderList:\n",
    "    fileList=glob(folder + '/*.jpg') # 경로+폴더명 \n",
    "\n",
    "    for file in fileList:\n",
    "    \n",
    "        fileName=file\n",
    "        tmp=folder.split('\\\\')[-1]  # 폴더명(경로 제외) \n",
    "        colorName=tmp.split('_')[0] # 폴더명 중 색상 \n",
    "        categoryName=tmp.split('_')[1] # 폴더명 중 카테고리(옷 정보)\n",
    "\n",
    "        # 파일 정보를 딕셔너리로 변경 \n",
    "        dataList.append({'Name':fileName,\n",
    "                        'colrName':colorName,\n",
    "                        'category':categoryName})\n",
    "# Dataframe 만들기 \n",
    "df=pd.DataFrame(dataList)\n",
    "\n",
    "# df를 dummy 파일로 만들기 \n",
    "# pd.get_dummies(df[['colrName','category'])==> 지정한 필드만 출력\n",
    "df=pd.get_dummies(df, columns=['colrName','category'])  # =>  전체데이터중 columns에 있는 필드만 처리되어서 모든 필드 다 출력\n",
    "\n",
    "# column명 변경 \n",
    "# (예) 기존: color_black> 변경: black\n",
    "df.columns=['Name', 'black', 'blue', 'brown', 'green', 'red', 'white', 'dress','pants', 'shirt', 'shoes','shorts']\n",
    "\n",
    "# csv파일로 저장 \n",
    "df.to_csv('data_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 파일정보 csv가 있을 때 npz자료로 제작하는 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- npz를 제작하기 위해 필요한 정보 \n",
    "    1. 이미지\n",
    "    2. 이미지 레이블 정보 (cvs로 제공)\n",
    "        - train.csv / test.csv / val.csv 자료로 작업 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고: 흐름 정리 \n",
    "    - 나중에 회사 가서 기술 요약서 등을 적을 때 이렇게 해야하므로 정리해줌 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-10-17-19-05-17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 아래 코드는 방식만 설명하기 위해서 적은 코딩임\n",
    "\n",
    "** 흐름과 코드의 원리 등을 참고만 할 것! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from PIL import Image \n",
    "\n",
    "df=pd.read_csv('train.csv')\n",
    "for x in df['Image']:\n",
    "    img=Image.open(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\ML\\00 공부한거\\221017_0. 통합 정리본_sk.ipynb 셀 20\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ML/00%20%EA%B3%B5%EB%B6%80%ED%95%9C%EA%B1%B0/221017_0.%20%ED%86%B5%ED%95%A9%20%EC%A0%95%EB%A6%AC%EB%B3%B8_sk.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ML/00%20%EA%B3%B5%EB%B6%80%ED%95%9C%EA%B1%B0/221017_0.%20%ED%86%B5%ED%95%A9%20%EC%A0%95%EB%A6%AC%EB%B3%B8_sk.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m val\u001b[39m=\u001b[39m[]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ML/00%20%EA%B3%B5%EB%B6%80%ED%95%9C%EA%B1%B0/221017_0.%20%ED%86%B5%ED%95%A9%20%EC%A0%95%EB%A6%AC%EB%B3%B8_sk.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mval.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ML/00%20%EA%B3%B5%EB%B6%80%ED%95%9C%EA%B1%B0/221017_0.%20%ED%86%B5%ED%95%A9%20%EC%A0%95%EB%A6%AC%EB%B3%B8_sk.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X\u001b[39m=\u001b[39m[]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ML/00%20%EA%B3%B5%EB%B6%80%ED%95%9C%EA%B1%B0/221017_0.%20%ED%86%B5%ED%95%A9%20%EC%A0%95%EB%A6%AC%EB%B3%B8_sk.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\han\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'val.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "\n",
    "val=[]\n",
    "df=pd.read_csv('val.csv')\n",
    "\n",
    "X=[]\n",
    "for x in df['Image']:\n",
    "    img=Image.open(x)\n",
    "    img=img.resize((180,180))\n",
    "    imgArr=np.array(img)\n",
    "    X.append(imgArr)\n",
    "\n",
    "color,category=[],[]\n",
    "color.append(df[['black', 'blue', 'brown', 'green', 'red', 'white']].values)\n",
    "category.append(df[['dress','pants', 'shirt', 'shoes','shorts']].values)\n",
    "\n",
    "val.append(X)\n",
    "val.append(color)\n",
    "val.append(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('han')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ffd841040af6bedd50cabf1584399d13f777232c008d7c4ad470663779a547a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
